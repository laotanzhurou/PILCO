50 sample completed in 26.90000891685486 seconds
episode:1, state: [92.05197906 -6.28439856 -2.51957893 45.        ], action: 1.98, score: -2.0
next state: [91.73371887 -6.40524817 -2.41699219 46.97999954], reward: -1.0
50 sample completed in 26.89794659614563 seconds
episode:2, state: [91.73371887 -6.40524817 -2.41699219 46.97999954], action: 1.98, score: -2.0
next state: [91.40942383 -6.52620697 -2.4191761  48.95999908], reward: -1.0
50 sample completed in 26.99303364753723 seconds
episode:3, state: [91.40942383 -6.52620697 -2.4191761  48.95999908], action: 1.98, score: -2.0
next state: [91.07925415 -6.64230013 -2.32186317 50.93999863], reward: -1.0
50 sample completed in 26.935991525650024 seconds
episode:4, state: [91.07925415 -6.64230013 -2.32186317 50.93999863], action: 1.98, score: -2.0
next state: [90.74327087 -6.7582159  -2.31831551 52.91999817], reward: -1.0
50 sample completed in 26.685696840286255 seconds
episode:5, state: [90.74327087 -6.7582159  -2.31831551 52.91999817], action: -1.98, score: -2.0
next state: [90.40164948 -6.87003899 -2.23646164 50.93999863], reward: -1.0
50 sample completed in 27.09296226501465 seconds
episode:6, state: [90.40164948 -6.87003899 -2.23646164 50.93999863], action: 1.98, score: -2.0
next state: [90.05445862 -6.98086882 -2.2165966  52.91999817], reward: -1.0
50 sample completed in 26.962461233139038 seconds
episode:7, state: [90.05445862 -6.98086882 -2.2165966  52.91999817], action: 1.98, score: -2.0
next state: [89.70184326 -7.08843899 -2.15140343 54.89999771], reward: -1.0
50 sample completed in 27.222821712493896 seconds
episode:8, state: [89.70184326 -7.08843899 -2.15140343 54.89999771], action: 1.98, score: -2.0
next state: [89.34532928 -7.11210918 -0.47340393 56.87999725], reward: -1.0
50 sample completed in 96.90191459655762 seconds
episode:9, state: [89.34532928 -7.11210918 -0.47340393 56.87999725], action: 1.98, score: -4.625
next state: [88.98845673 -7.16178513 -0.99351883 58.8599968 ], reward: -1.0
50 sample completed in 58.30601382255554 seconds
episode:10, state: [88.98845673 -7.16178513 -0.99351883 58.8599968 ], action: -1.98, score: -3.12
next state: [88.63320923 -7.08022404  1.63122177 56.87999725], reward: -1.0
50 sample completed in 102.52468276023865 seconds
episode:11, state: [88.63320923 -7.08022404  1.63122177 56.87999725], action: -1.98, score: -4.8
next state: [88.27931213 -7.06330252  0.3384304  54.89999771], reward: -1.0
50 sample completed in 105.41235971450806 seconds
episode:12, state: [88.27931213 -7.06330252  0.3384304  54.89999771], action: 1.98, score: -4.916666666666667
next state: [87.94037628 -6.63585901  8.54887009 56.87999725], reward: -1.0
50 sample completed in 100.01236724853516 seconds
episode:13, state: [87.94037628 -6.63585901  8.54887009 56.87999725], action: -1.98, score: -4.679999999999999
next state: [87.62448883 -6.15200186  9.6771431  54.89999771], reward: -1.0
50 sample completed in 100.55967617034912 seconds
episode:14, state: [87.62448883 -6.15200186  9.6771431  54.89999771], action: 1.98, score: -4.791666666666665
next state: [87.34406281 -5.37418318 15.5563736  56.87999725], reward: -1.0
50 sample completed in 103.88235449790955 seconds
episode:15, state: [87.34406281 -5.37418318 15.5563736  56.87999725], action: -1.98, score: -4.88
next state: [87.10041809 -4.65354538 14.41275597 54.89999771], reward: -1.0
50 sample completed in 104.52567672729492 seconds
episode:16, state: [87.10041809 -4.65354538 14.41275597 54.89999771], action: 1.98, score: -4.916666666666667
next state: [86.89380646 -3.90359449 14.99901772 56.87999725], reward: -1.0
50 sample completed in 101.38290429115295 seconds
episode:17, state: [86.89380646 -3.90359449 14.99901772 56.87999725], action: 1.98, score: -4.68
next state: [86.72437286 -3.15852571 14.90137577 58.8599968 ], reward: -1.0
50 sample completed in 96.57909631729126 seconds
episode:18, state: [86.72437286 -3.15852571 14.90137577 58.8599968 ], action: -1.98, score: -3.88
next state: [86.58716583 -2.69559908  9.25853252 56.87999725], reward: -1.0
50 sample completed in 26.253679513931274 seconds
episode:19, state: [86.58716583 -2.69559908  9.25853252 56.87999725], action: 1.98, score: -1.0
next state: [ 86.43286133  -3.21650362 -10.41809082  58.8599968 ], reward: -1.0
50 sample completed in 97.76235890388489 seconds
episode:20, state: [ 86.43286133  -3.21650362 -10.41809082  58.8599968 ], action: 1.98, score: -4.68
next state: [86.2649765  -3.35431552 -2.75623798 60.83999634], reward: -1.0
50 sample completed in 99.96806502342224 seconds
episode:21, state: [86.2649765  -3.35431552 -2.75623798 60.83999634], action: -1.98, score: -4.750000000000001
next state: [86.10128021 -3.18836355  3.31903934 58.8599968 ], reward: -1.0
50 sample completed in 97.64172983169556 seconds
episode:22, state: [86.10128021 -3.18836355  3.31903934 58.8599968 ], action: 1.98, score: -4.52
next state: [85.95269012 -2.84282374  6.91079617 60.83999634], reward: -1.0
50 sample completed in 102.40999412536621 seconds
episode:23, state: [85.95269012 -2.84282374  6.91079617 60.83999634], action: -1.98, score: -4.88
next state: [85.82555389 -2.38869977  9.08247948 58.8599968 ], reward: -1.0
50 sample completed in 26.51333498954773 seconds
episode:24, state: [85.82555389 -2.38869977  9.08247948 58.8599968 ], action: 1.98, score: -1.0
next state: [85.72374725 -1.86644709 10.4450531  60.83999634], reward: -1.0
50 sample completed in 26.314337491989136 seconds
episode:25, state: [85.72374725 -1.86644709 10.4450531  60.83999634], action: 1.98, score: -1.0
next state: [85.64970398 -1.30140543 11.30083275 62.81999588], reward: -1.0
50 sample completed in 26.41612195968628 seconds
episode:26, state: [85.64970398 -1.30140543 11.30083275 62.81999588], action: -1.98, score: -1.0
next state: [85.60837555 -0.55632675 14.90157318 60.83999634], reward: -1.0
50 sample completed in 96.1944260597229 seconds
episode:27, state: [85.60837555 -0.55632675 14.90157318 60.83999634], action: -1.98, score: -4.32
next state: [ 8.56017838e+01 -6.19474379e-03  1.10026398e+01  5.88599968e+01], reward: -1.0
50 sample completed in 26.78824257850647 seconds
episode:28, state: [ 8.56017838e+01 -6.19474379e-03  1.10026398e+01  5.88599968e+01], action: -1.98, score: -1.0
next state: [8.56016693e+01 1.95126585e-03 1.62920192e-01 5.68799973e+01], reward: -1.0
final state: [ 7.19916534e-01 -1.95126585e-04  6.61235994e-01  1.19799995e+00]
final reward: -1.0
planning completed, exiting...